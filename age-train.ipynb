{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlib\n",
    "import cv2\n",
    "import imutils\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "import shutil\n",
    "import scipy.io\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, Input, Convolution2D, ZeroPadding2D, MaxPooling2D, Activation\n",
    "from keras.layers import Conv2D, AveragePooling2D\n",
    "from keras.models import Model, Sequential\n",
    "\n",
    "\n",
    "target_size = (224, 224)\n",
    "\n",
    "# fotografta yuz var mi kontrolu\n",
    "def check_detection(img):\n",
    "    exact_image = False\n",
    "    if type(img).__module__ == np.__name__:\n",
    "        exact_image = True\n",
    "\n",
    "    base64_img = False\n",
    "    if len(img) > 11 and img[0:11] == \"data:image/\":\n",
    "        base64_img = True\n",
    "\n",
    "\n",
    "    elif not exact_image:  # image path passed as input\n",
    "\n",
    "        if not os.path.isfile(img):\n",
    "            raise ValueError(\"Confirm that \", img, \" exists\")\n",
    "\n",
    "        img = cv2.imread(img)\n",
    "\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    rects, scores, idx = face_detector.run(gray,1,-1)\n",
    "            \n",
    "    if len(rects) > 0:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "# yuz tespit eden fonksyion\n",
    "def detect_face(img):\n",
    "    exact_image = False\n",
    "    if type(img).__module__ == np.__name__:\n",
    "        exact_image = True\n",
    "\n",
    "    base64_img = False\n",
    "    if len(img) > 11 and img[0:11] == \"data:image/\":\n",
    "        base64_img = True\n",
    "\n",
    "    elif not exact_image:  # image path passed as input\n",
    "        if not os.path.isfile(img):\n",
    "            raise ValueError(\"Confirm that \", img, \" exists\")\n",
    "\n",
    "        img = cv2.imread(img)\n",
    "\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # rects: yuz tespiti yapilan cerceve\n",
    "    # scores: yuz tespiti skorlari\n",
    "    # best_score_index: en yuksek skora sahip yuzun indisi\n",
    "    rects, scores, idx = face_detector.run(gray,1,-1)\n",
    "    best_score_index = np.argmax(scores)\n",
    "    faces = []\n",
    "    # tespit edilen yuzler fotograftan kirpiliyor \n",
    "    for rect in rects:\n",
    "        detected_face = img[max(0, rect.top()): min(rect.bottom(), img.shape[0]),\n",
    "                    max(0, rect.left()): min(rect.right(), img.shape[1])]\n",
    "        \n",
    "        # fotograflar 224, 224 hale getiriliyor\n",
    "        detected_face = cv2.resize(detected_face, (target_size[0], target_size[1]))\n",
    "        faces.append(detected_face)\n",
    "\n",
    "    return faces[best_score_index]\n",
    "\n",
    "# veri setindeki fotograflarin yasini hesaplayan fonksiyon\n",
    "def datenum_to_datetime(datenum):\n",
    "    days = datenum % 1\n",
    "\n",
    "    hours = days % 1 * 24\n",
    "    minutes = hours % 1 * 60\n",
    "    seconds = minutes % 1 * 60\n",
    "    exact_date = datetime.fromordinal(int(datenum)) \\\n",
    "                 + timedelta(days=int(days)) + timedelta(hours=int(hours)) \\\n",
    "                 + timedelta(minutes=int(minutes)) + timedelta(seconds=round(seconds)) \\\n",
    "                 - timedelta(days=366)\n",
    "\n",
    "    return exact_date.year\n",
    "\n",
    "# goruntuleri egitim icin uygun formata getiren fonksiyon\n",
    "def preprocess_pixels(img_pixels):\n",
    "    img_pixels = np.expand_dims(img_pixels, axis=0)\n",
    "    return img_pixels\n",
    "\n",
    "# tahmin olasiliklarini kendi indisleriyle carparak yas tahmini ureten fonksiyon\n",
    "def findApparentAge(age_predictions):\n",
    "    output_indexes = np.array([i for i in range(0, 101)])\n",
    "\n",
    "    apparent_age = np.sum(age_predictions * output_indexes)\n",
    "\n",
    "    return apparent_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verinin okunmasi\n",
    "mat = scipy.io.loadmat('wiki_crop/wiki.mat')\n",
    "instances = mat['wiki'][0][0][0].shape[1]\n",
    "\n",
    "columns = [\"dob\", \"photo_taken\", \"full_path\", \"gender\", \"name\", \"face_location\", \"face_score\", \"second_face_score\"]\n",
    "df = pd.DataFrame(index=range(0, instances), columns=columns)\n",
    "\n",
    "for i in mat:\n",
    "    if i == \"wiki\":\n",
    "        current_array = mat[i][0][0]\n",
    "for j in range(len(current_array)):\n",
    "    df[columns[j]] = pd.DataFrame(current_array[j][0])\n",
    "\n",
    "df['date_of_birth'] = df['dob'].apply(datenum_to_datetime)\n",
    "df['age'] = df['photo_taken'] - df['date_of_birth']\n",
    "# yuzu olmayan fotograflar cikartiliyor\n",
    "df = df[df['face_score'] != -np.inf]\n",
    "\n",
    "# birden fazla yuz barindiran fotograflar cikartiliyor\n",
    "df = df[df['second_face_score'].isna()]\n",
    "\n",
    "# yuz skoru threshold altinda kalanlar cikartiliyor\n",
    "df = df[df['face_score'] >= 3]\n",
    "\n",
    "# cinsiyeti olmayan fotograflar cikartiliyor\n",
    "df = df[~df['gender'].isna()]\n",
    "\n",
    "df = df.drop(\n",
    "    columns=['name', 'face_score', 'second_face_score', 'date_of_birth', 'face_location', 'dob', 'photo_taken'])\n",
    "# 0 - 100 yas araliginda olmayanlar cikartiliyor\n",
    "df = df[df['age'] <= 100]\n",
    "df = df[df['age'] > 0]\n",
    "\n",
    "paths = []\n",
    "for index, i in enumerate(df['full_path']):\n",
    "    paths.append(i[0])\n",
    "df['path'] = paths\n",
    "df['path'] = \"wiki_crop/\" + df['path']\n",
    "df = df.drop(columns=['full_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>28</td>\n",
       "      <td>wiki_crop/17/10000217_1981-05-05_2009.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>60</td>\n",
       "      <td>wiki_crop/12/100012_1948-07-03_2008.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>41</td>\n",
       "      <td>wiki_crop/16/10002116_1971-05-31_2012.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>52</td>\n",
       "      <td>wiki_crop/02/10002702_1960-11-09_2012.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>34</td>\n",
       "      <td>wiki_crop/41/10003541_1937-09-27_1971.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender  age                                       path\n",
       "0     1.0   28  wiki_crop/17/10000217_1981-05-05_2009.jpg\n",
       "2     1.0   60    wiki_crop/12/100012_1948-07-03_2008.jpg\n",
       "4     0.0   41  wiki_crop/16/10002116_1971-05-31_2012.jpg\n",
       "5     0.0   52  wiki_crop/02/10002702_1960-11-09_2012.jpg\n",
       "6     1.0   34  wiki_crop/41/10003541_1937-09-27_1971.jpg"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yuz tespiti icin detektor \n",
    "face_detector = dlib.get_frontal_face_detector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python38\\lib\\site-packages\\tqdm\\std.py:668: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 22138/22138 [13:08<00:00, 28.08it/s]\n"
     ]
    }
   ],
   "source": [
    "# fotograflarda yuz tespitinin yapilabilir oldugu kontrol ediliyor\n",
    "tqdm.pandas()\n",
    "df['detection'] = df['path'].progress_apply(check_detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     22124\n",
       "False       14\n",
       "Name: detection, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# yuz tespiti yapilan ve yapilamayan fotograf sayisi\n",
    "df['detection'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yuz tespiti yapilamayanlar cikartiliyor\n",
    "df = df[df.detection == True]\n",
    "df = df.drop(columns='detection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = 101\n",
    "target = df['age'].values\n",
    "target_classes = keras.utils.to_categorical(target, classes)\n",
    "\n",
    "features = []\n",
    "\n",
    "for i in range(0, df.shape[0]):\n",
    "    features.append(df['path'].values[i])\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(features, target_classes, test_size=0.20)\n",
    "\n",
    "a = len(train_x)\n",
    "temp_list = []\n",
    "# veri setinde yuz tespiti yapiliyor\n",
    "for index, i in enumerate(train_x):\n",
    "    # gidisat takibi icin adim sayisi yazdiriliyor\n",
    "    print(f'{index}/{a}')\n",
    "    \n",
    "    img = detect_face(i)\n",
    "    temp_list.append(img)\n",
    "\n",
    "train_x = temp_list\n",
    "temp_list2 = []\n",
    "a = len(test_x)   \n",
    "\n",
    "for index, i in enumerate(test_x):\n",
    "    print(f'{index}/{a}')\n",
    "    \n",
    "    img = detect_face(i)\n",
    "    temp_list2.append(img)\n",
    "\n",
    "test_x = temp_list2\n",
    "\n",
    "# veriler uygun formata getiriliyor. (bu kisim biraz fazla memory tuketebilir)\n",
    "train_x = np.array(train_x)/255\n",
    "test_x = np.array(test_x)/255\n",
    "\n",
    "train_x, val_x, train_y, val_y = train_test_split(train_x, train_y\n",
    "                                        , test_size=0.1, random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vgg face modeli\n",
    "model = Sequential()\n",
    "model.add(ZeroPadding2D((1, 1), input_shape=(224, 224, 3)))\n",
    "model.add(Convolution2D(64, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(128, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(Convolution2D(4096, (7, 7), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Convolution2D(4096, (1, 1), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Convolution2D(2622, (1, 1)))\n",
    "model.add(Flatten())\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.load_weights('vgg_face_weights.h5')\n",
    "\n",
    "for layer in model.layers[:-7]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# yeniden egitim icin son katmanlar eklendi \n",
    "base_model_output = Sequential()\n",
    "base_model_output = Convolution2D(classes, (1, 1), name='predictions')(model.layers[-4].output)\n",
    "base_model_output = Flatten()(base_model_output)\n",
    "base_model_output = Activation('softmax')(base_model_output)\n",
    "\n",
    "age_model = Model(inputs=model.input, outputs=base_model_output)\n",
    "\n",
    "age_model.compile(loss='categorical_crossentropy'\n",
    "                  , optimizer=keras.optimizers.Adam()\n",
    "                  , metrics=['accuracy']\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "498/498 [==============================] - ETA: 0s - loss: 3.7672 - accuracy: 0.0466\n",
      "Epoch 00001: val_loss improved from inf to 3.62164, saving model to models/age_new.hdf5\n",
      "498/498 [==============================] - 201s 404ms/step - loss: 3.7672 - accuracy: 0.0466 - val_loss: 3.6216 - val_accuracy: 0.0486\n",
      "Epoch 2/10\n",
      "498/498 [==============================] - ETA: 0s - loss: 3.6424 - accuracy: 0.0521\n",
      "Epoch 00002: val_loss did not improve from 3.62164\n",
      "498/498 [==============================] - 201s 404ms/step - loss: 3.6424 - accuracy: 0.0521 - val_loss: 3.6234 - val_accuracy: 0.0554\n",
      "Epoch 3/10\n",
      "498/498 [==============================] - ETA: 0s - loss: 3.5598 - accuracy: 0.0597\n",
      "Epoch 00003: val_loss improved from 3.62164 to 3.55173, saving model to models/age_new.hdf5\n",
      "498/498 [==============================] - 206s 414ms/step - loss: 3.5598 - accuracy: 0.0597 - val_loss: 3.5517 - val_accuracy: 0.0565\n",
      "Epoch 4/10\n",
      "498/498 [==============================] - ETA: 0s - loss: 3.4849 - accuracy: 0.0724\n",
      "Epoch 00004: val_loss improved from 3.55173 to 3.51237, saving model to models/age_new.hdf5\n",
      "498/498 [==============================] - 187s 376ms/step - loss: 3.4849 - accuracy: 0.0724 - val_loss: 3.5124 - val_accuracy: 0.0616\n",
      "Epoch 5/10\n",
      "498/498 [==============================] - ETA: 0s - loss: 3.4060 - accuracy: 0.0778\n",
      "Epoch 00005: val_loss did not improve from 3.51237\n",
      "498/498 [==============================] - 181s 364ms/step - loss: 3.4060 - accuracy: 0.0778 - val_loss: 3.5396 - val_accuracy: 0.0480\n",
      "Epoch 6/10\n",
      "498/498 [==============================] - ETA: 0s - loss: 3.3545 - accuracy: 0.0878\n",
      "Epoch 00006: val_loss improved from 3.51237 to 3.51134, saving model to models/age_new.hdf5\n",
      "498/498 [==============================] - 184s 370ms/step - loss: 3.3545 - accuracy: 0.0878 - val_loss: 3.5113 - val_accuracy: 0.0537\n",
      "Epoch 7/10\n",
      "498/498 [==============================] - ETA: 0s - loss: 3.3017 - accuracy: 0.1016\n",
      "Epoch 00007: val_loss improved from 3.51134 to 3.50396, saving model to models/age_new.hdf5\n",
      "498/498 [==============================] - 185s 371ms/step - loss: 3.3017 - accuracy: 0.1016 - val_loss: 3.5040 - val_accuracy: 0.0576\n",
      "Epoch 8/10\n",
      "498/498 [==============================] - ETA: 0s - loss: 3.2379 - accuracy: 0.1082\n",
      "Epoch 00008: val_loss did not improve from 3.50396\n",
      "498/498 [==============================] - 193s 388ms/step - loss: 3.2379 - accuracy: 0.1082 - val_loss: 3.5195 - val_accuracy: 0.0554\n",
      "Epoch 9/10\n",
      "498/498 [==============================] - ETA: 0s - loss: 3.2067 - accuracy: 0.1167\n",
      "Epoch 00009: val_loss did not improve from 3.50396\n",
      "498/498 [==============================] - 213s 428ms/step - loss: 3.2067 - accuracy: 0.1167 - val_loss: 3.5048 - val_accuracy: 0.0520\n",
      "Epoch 10/10\n",
      "498/498 [==============================] - ETA: 0s - loss: 3.1485 - accuracy: 0.1249\n",
      "Epoch 00010: val_loss did not improve from 3.50396\n",
      "498/498 [==============================] - 190s 382ms/step - loss: 3.1485 - accuracy: 0.1249 - val_loss: 3.5089 - val_accuracy: 0.0621\n"
     ]
    }
   ],
   "source": [
    "# /models klasoru olmasi gereklidir. Her tur sonunda en iyi model kontrolu yapilarak kaydedilecektir. \n",
    "checkpointer = ModelCheckpoint(\n",
    "    filepath='models/age.hdf5'\n",
    "    , monitor=\"val_loss\"\n",
    "    , verbose=1\n",
    "    , save_best_only=True\n",
    "    , mode='auto'\n",
    ")\n",
    "\n",
    "# patience early stopping icin gerekli,\n",
    "# val_loss'un azalmasinin kac epoch beklenecegini belirtir. Azalmazsa egitimi durdurur.\n",
    "patience = 5\n",
    "epochs = 10\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=patience)\n",
    "\n",
    "score = age_model.fit(\n",
    "        train_x, train_y\n",
    "        , epochs=epochs\n",
    "        , validation_data=(val_x, val_y)\n",
    "        , callbacks=[checkpointer, early_stop]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# en iyi model tekrar yuleniyor\n",
    "from keras.models import load_model\n",
    "age_model = load_model('models/age.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139/139 [==============================] - 36s 259ms/step - loss: 3.4479 - accuracy: 0.0592\n"
     ]
    }
   ],
   "source": [
    "score = age_model.evaluate(test_x, test_y, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[-5,+5] araligindaki test islemi bu kisimda yapilabilir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trues = 0\n",
    "a = len(test_x)\n",
    "for index, i in enumerate(test_x):\n",
    "    print(f'{index}/{a}')\n",
    "\n",
    "    img_pixels = preprocess_pixels(i)\n",
    "    age_predictions = age_model.predict(img_pixels)[0, :]\n",
    "    apparent_age = findApparentAge(age_predictions)\n",
    "    if apparent_age-5 <= test_y[index].argmax() <= apparent_age+5:\n",
    "        trues += 1\n",
    "print(f'acc:{100*trues/len(test_x)}%')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
